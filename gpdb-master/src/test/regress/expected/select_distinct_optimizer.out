--
-- SELECT_DISTINCT
--
--
-- awk '{print $3;}' onek.data | sort -n | uniq
--
SELECT DISTINCT two FROM tmp ORDER BY 1;
 two 
-----
   0
   1
(2 rows)

--
-- awk '{print $5;}' onek.data | sort -n | uniq
--
SELECT DISTINCT ten FROM tmp ORDER BY 1;
 ten 
-----
   0
   1
   2
   3
   4
   5
   6
   7
   8
   9
(10 rows)

--
-- awk '{print $16;}' onek.data | sort -d | uniq
--
SELECT DISTINCT string4 FROM tmp ORDER BY 1;
 string4 
---------
 AAAAxx
 HHHHxx
 OOOOxx
 VVVVxx
(4 rows)

--
-- awk '{print $3,$16,$5;}' onek.data | sort -d | uniq |
-- sort +0n -1 +1d -2 +2n -3
--
SELECT DISTINCT two, string4, ten
   FROM tmp
   ORDER BY two using <, string4 using <, ten using <;
 two | string4 | ten 
-----+---------+-----
   0 | AAAAxx  |   0
   0 | AAAAxx  |   2
   0 | AAAAxx  |   4
   0 | AAAAxx  |   6
   0 | AAAAxx  |   8
   0 | HHHHxx  |   0
   0 | HHHHxx  |   2
   0 | HHHHxx  |   4
   0 | HHHHxx  |   6
   0 | HHHHxx  |   8
   0 | OOOOxx  |   0
   0 | OOOOxx  |   2
   0 | OOOOxx  |   4
   0 | OOOOxx  |   6
   0 | OOOOxx  |   8
   0 | VVVVxx  |   0
   0 | VVVVxx  |   2
   0 | VVVVxx  |   4
   0 | VVVVxx  |   6
   0 | VVVVxx  |   8
   1 | AAAAxx  |   1
   1 | AAAAxx  |   3
   1 | AAAAxx  |   5
   1 | AAAAxx  |   7
   1 | AAAAxx  |   9
   1 | HHHHxx  |   1
   1 | HHHHxx  |   3
   1 | HHHHxx  |   5
   1 | HHHHxx  |   7
   1 | HHHHxx  |   9
   1 | OOOOxx  |   1
   1 | OOOOxx  |   3
   1 | OOOOxx  |   5
   1 | OOOOxx  |   7
   1 | OOOOxx  |   9
   1 | VVVVxx  |   1
   1 | VVVVxx  |   3
   1 | VVVVxx  |   5
   1 | VVVVxx  |   7
   1 | VVVVxx  |   9
(40 rows)

--
-- awk '{print $2;}' person.data |
-- awk '{if(NF!=1){print $2;}else{print;}}' - emp.data |
-- awk '{if(NF!=1){print $2;}else{print;}}' - student.data |
-- awk 'BEGIN{FS="      ";}{if(NF!=1){print $5;}else{print;}}' - stud_emp.data |
-- sort -n -r | uniq
--
SELECT DISTINCT p.age FROM person* p ORDER BY age using >;
 age 
-----
  98
  88
  78
  68
  60
  58
  50
  48
  40
  38
  34
  30
  28
  25
  24
  23
  20
  19
  18
   8
(20 rows)

--
-- Check mentioning same column more than once
--
EXPLAIN (VERBOSE, COSTS OFF)
SELECT count(*) FROM
  (SELECT DISTINCT two, four, two FROM tenk1) ss;
                                 QUERY PLAN                                  
-----------------------------------------------------------------------------
 Aggregate
   Output: count()
   ->  Gather Motion 3:1  (slice1; segments: 3)
         ->  GroupAggregate
               Group Key: tenk1.two, tenk1.four, tenk1.two
               ->  Sort
                     Output: two, four
                     Sort Key: tenk1.two, tenk1.four, tenk1.two
                     ->  Redistribute Motion 3:3  (slice2; segments: 3)
                           Output: two, four
                           Hash Key: two, four, two
                           ->  Streaming HashAggregate
                                 Output: two, four
                                 Group Key: tenk1.two, tenk1.four, tenk1.two
                                 ->  Seq Scan on public.tenk1
                                       Output: two, four
 Optimizer: Pivotal Optimizer (GPORCA) version 3.83.0
 Settings: optimizer=on
(18 rows)

SELECT count(*) FROM
  (SELECT DISTINCT two, four, two FROM tenk1) ss;
 count 
-------
     4
(1 row)

--
-- Compare results between plans using sorting and plans using hash
-- aggregation. Force spilling in both cases by setting work_mem low.
--
SET work_mem='64kB';
WARNING:  "work_mem": setting is deprecated, and may be removed in a future release.
-- Produce results with sorting.
SET enable_hashagg=FALSE;
SET optimizer_enable_hashagg=FALSE;
SET jit_above_cost=0;
EXPLAIN (costs off)
SELECT DISTINCT g%1000 FROM generate_series(0,9999) g;
                  QUERY PLAN                  
----------------------------------------------
 GroupAggregate
   Group Key: ((generate_series % 1000))
   ->  Sort
         Sort Key: ((generate_series % 1000))
         ->  Function Scan on generate_series
 Optimizer: Pivotal Optimizer (GPORCA)
(6 rows)

CREATE TABLE distinct_group_1 AS
SELECT DISTINCT g%1000 FROM generate_series(0,9999) g;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause. Creating a NULL policy entry.
SET jit_above_cost TO DEFAULT;
CREATE TABLE distinct_group_2 AS
SELECT DISTINCT (g%1000)::text FROM generate_series(0,9999) g;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause. Creating a NULL policy entry.
SET enable_hashagg=TRUE;
SET optimizer_enable_hashagg=TRUE;
-- Produce results with hash aggregation.
SET enable_sort=FALSE;
SET jit_above_cost=0;
EXPLAIN (costs off)
SELECT DISTINCT g%1000 FROM generate_series(0,9999) g;
               QUERY PLAN               
----------------------------------------
 HashAggregate
   Group Key: (generate_series % 1000)
   ->  Function Scan on generate_series
 Optimizer: Pivotal Optimizer (GPORCA)
(4 rows)

CREATE TABLE distinct_hash_1 AS
SELECT DISTINCT g%1000 FROM generate_series(0,9999) g;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause. Creating a NULL policy entry.
SET jit_above_cost TO DEFAULT;
CREATE TABLE distinct_hash_2 AS
SELECT DISTINCT (g%1000)::text FROM generate_series(0,9999) g;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause. Creating a NULL policy entry.
SET enable_sort=TRUE;
SET work_mem TO DEFAULT;
WARNING:  "work_mem": setting is deprecated, and may be removed in a future release.
-- Compare results
(SELECT * FROM distinct_hash_1 EXCEPT SELECT * FROM distinct_group_1)
  UNION ALL
(SELECT * FROM distinct_group_1 EXCEPT SELECT * FROM distinct_hash_1);
 ?column? 
----------
(0 rows)

(SELECT * FROM distinct_hash_1 EXCEPT SELECT * FROM distinct_group_1)
  UNION ALL
(SELECT * FROM distinct_group_1 EXCEPT SELECT * FROM distinct_hash_1);
 ?column? 
----------
(0 rows)

DROP TABLE distinct_hash_1;
DROP TABLE distinct_hash_2;
DROP TABLE distinct_group_1;
DROP TABLE distinct_group_2;
--
-- Also, some tests of IS DISTINCT FROM, which doesn't quite deserve its
-- very own regression file.
--
CREATE TEMP TABLE disttable (f1 integer);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'f1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
INSERT INTO DISTTABLE VALUES(1);
INSERT INTO DISTTABLE VALUES(2);
INSERT INTO DISTTABLE VALUES(3);
INSERT INTO DISTTABLE VALUES(NULL);
-- basic cases
SELECT f1, f1 IS DISTINCT FROM 2 as "not 2" FROM disttable;
 f1 | not 2 
----+-------
  2 | f
  3 | t
    | t
  1 | t
(4 rows)

SELECT f1, f1 IS DISTINCT FROM NULL as "not null" FROM disttable;
 f1 | not null 
----+----------
  2 | t
  3 | t
    | f
  1 | t
(4 rows)

SELECT f1, f1 IS DISTINCT FROM f1 as "false" FROM disttable;
 f1 | false 
----+-------
  2 | f
  3 | f
    | f
  1 | f
(4 rows)

SELECT f1, f1 IS DISTINCT FROM f1+1 as "not null" FROM disttable;
 f1 | not null 
----+----------
  2 | t
  3 | t
    | f
  1 | t
(4 rows)

-- check that optimizer constant-folds it properly
SELECT 1 IS DISTINCT FROM 2 as "yes";
 yes 
-----
 t
(1 row)

SELECT 2 IS DISTINCT FROM 2 as "no";
 no 
----
 f
(1 row)

SELECT 2 IS DISTINCT FROM null as "yes";
 yes 
-----
 t
(1 row)

SELECT null IS DISTINCT FROM null as "no";
 no 
----
 f
(1 row)

-- negated form
SELECT 1 IS NOT DISTINCT FROM 2 as "no";
 no 
----
 f
(1 row)

SELECT 2 IS NOT DISTINCT FROM 2 as "yes";
 yes 
-----
 t
(1 row)

SELECT 2 IS NOT DISTINCT FROM null as "no";
 no 
----
 f
(1 row)

SELECT null IS NOT DISTINCT FROM null as "yes";
 yes 
-----
 t
(1 row)

-- gpdb start: test inherit/partition table distinct when gp_statistics_pullup_from_child_partition is on
set gp_statistics_pullup_from_child_partition to on;
CREATE TABLE sales (id int, date date, amt decimal(10,2))
DISTRIBUTED BY (id);
insert into sales values (1,'20210202',20), (2,'20210602',9) ,(3,'20211002',100);
select distinct * from sales order by 1;
 id |    date    |  amt   
----+------------+--------
  1 | 02-02-2021 |  20.00
  2 | 06-02-2021 |   9.00
  3 | 10-02-2021 | 100.00
(3 rows)

select distinct sales from sales order by 1;
         sales         
-----------------------
 (1,02-02-2021,20.00)
 (2,06-02-2021,9.00)
 (3,10-02-2021,100.00)
(3 rows)

CREATE TABLE sales_partition (id int, date date, amt decimal(10,2))
DISTRIBUTED BY (id)
PARTITION BY RANGE (date)
( START (date '2021-01-01') INCLUSIVE
  END (date '2022-01-01') EXCLUSIVE
  EVERY (INTERVAL '1 month') );
insert into sales_partition values (1,'20210202',20), (2,'20210602',9) ,(3,'20211002',100);
select distinct * from sales_partition order by 1;
 id |    date    |  amt   
----+------------+--------
  1 | 02-02-2021 |  20.00
  2 | 06-02-2021 |   9.00
  3 | 10-02-2021 | 100.00
(3 rows)

select distinct sales_partition from sales_partition order by 1;
    sales_partition    
-----------------------
 (1,02-02-2021,20.00)
 (2,06-02-2021,9.00)
 (3,10-02-2021,100.00)
(3 rows)

DROP TABLE sales;
DROP TABLE sales_partition;
CREATE TABLE cities (
    name            text,
    population      float,
    altitude        int
); 
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'name' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
CREATE TABLE capitals (
    state           char(2)
) INHERITS (cities);
NOTICE:  table has parent, setting distribution columns to match parent table
select distinct * from cities;
 name | population | altitude 
------+------------+----------
(0 rows)

select distinct cities from cities;
 cities 
--------
(0 rows)

DROP TABLE capitals;
DROP TABLE cities;
set gp_statistics_pullup_from_child_partition to off;
-- gpdb end: test inherit/partition table distinct when gp_statistics_pullup_from_child_partition is on
